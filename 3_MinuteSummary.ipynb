{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4. MinuteSummary",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kim-TaeKyoung/one/blob/main/3_MinuteSummary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS0pamX6QL9j",
        "outputId": "825138d1-9a32-4797-8909-45855ef06cb2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gAympNoV_M3"
      },
      "source": [
        "from glob import glob\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "FtZNRc5A8Bbi"
      },
      "source": [
        "#@title Smallest Enclosing Circle\n",
        "import numpy as np\n",
        " \n",
        "class ProjectorStack:\n",
        "    \"\"\"\n",
        "    Stack of points that are shifted / projected to put first one at origin.\n",
        "    \"\"\"\n",
        "    def __init__(self, vec):\n",
        "        self.vs = np.array(vec)\n",
        " \n",
        "    def push(self, v):\n",
        "        if len(self.vs) == 0:\n",
        "            self.vs = np.array([v])\n",
        "        else:\n",
        "            self.vs = np.append(self.vs, [v], axis=0)\n",
        "        return self\n",
        " \n",
        "    def pop(self):\n",
        "        if len(self.vs) > 0:\n",
        "            ret, self.vs = self.vs[-1], self.vs[:-1]\n",
        "            return ret\n",
        " \n",
        "    def __mul__(self, v):\n",
        "        s = np.zeros(len(v))\n",
        "        for vi in self.vs:\n",
        "            s = s + vi * np.dot(vi, v)\n",
        "        return s\n",
        " \n",
        "class GaertnerBoundary:\n",
        "    \"\"\"\n",
        "        GärtnerBoundary\n",
        " \n",
        "    See the passage regarding M_B in Section 4 of Gärtner's paper.\n",
        "    \"\"\"\n",
        "    def __init__(self, pts):\n",
        "        self.projector = ProjectorStack([])\n",
        "        self.centers, self.square_radii = np.array([]), np.array([])\n",
        "        self.empty_center = np.array([np.NaN for _ in pts[0]])\n",
        " \n",
        " \n",
        "def push_if_stable(bound, pt):\n",
        "    if len(bound.centers) == 0:\n",
        "        bound.square_radii = np.append(bound.square_radii, 0.0)\n",
        "        bound.centers = np.array([pt])\n",
        "        return True\n",
        "    q0, center = bound.centers[0], bound.centers[-1]\n",
        "    C, r2  = center - q0, bound.square_radii[-1]\n",
        "    Qm, M = pt - q0, bound.projector\n",
        "    Qm_bar = M * Qm\n",
        "    residue, e = Qm - Qm_bar, sqdist(Qm, C) - r2\n",
        "    z, tol = 2 * sqnorm(residue), np.finfo(float).eps * max(r2, 1.0)\n",
        "    isstable = np.abs(z) > tol\n",
        "    if isstable:\n",
        "        center_new  = center + (e / z) * residue\n",
        "        r2new = r2 + (e * e) / (2 * z)\n",
        "        bound.projector.push(residue / np.linalg.norm(residue))\n",
        "        bound.centers = np.append(bound.centers, np.array([center_new]), axis=0)\n",
        "        bound.square_radii = np.append(bound.square_radii, r2new)\n",
        "    return isstable\n",
        " \n",
        "def pop(bound):\n",
        "    n = len(bound.centers)\n",
        "    bound.centers = bound.centers[:-1]\n",
        "    bound.square_radii = bound.square_radii[:-1]\n",
        "    if n >= 2:\n",
        "        bound.projector.pop()\n",
        "    return bound\n",
        " \n",
        " \n",
        "class NSphere:\n",
        "    def __init__(self, c, sqr):\n",
        "        self.center = np.array(c)\n",
        "        self.sqradius = sqr\n",
        " \n",
        "def isinside(pt, nsphere, atol=1e-6, rtol=0.0):\n",
        "    r2, R2 = sqdist(pt, nsphere.center), nsphere.sqradius\n",
        "    return r2 <= R2 or np.isclose(r2, R2, atol=atol**2,rtol=rtol**2)\n",
        " \n",
        "def allinside(pts, nsphere, atol=1e-6, rtol=0.0):\n",
        "    for p in pts:\n",
        "        if not isinside(p, nsphere, atol, rtol):\n",
        "            return False\n",
        "    return True\n",
        " \n",
        "def move_to_front(pts, i):\n",
        "    pt = pts[i]\n",
        "    for j in range(len(pts)):\n",
        "        pts[j], pt = pt, np.array(pts[j])\n",
        "        if j == i:\n",
        "            break\n",
        "    return pts\n",
        " \n",
        "def dist(p1, p2):\n",
        "    return np.linalg.norm(p1 - p2)\n",
        " \n",
        "def sqdist(p1, p2):\n",
        "    return sqnorm(p1 - p2)\n",
        " \n",
        "def sqnorm(p):\n",
        "    return np.sum(np.array([x * x for x in p]))\n",
        " \n",
        "def ismaxlength(bound):\n",
        "    len(bound.centers) == len(bound.empty_center) + 1\n",
        " \n",
        "def makeNSphere(bound):\n",
        "    if len(bound.centers) == 0: \n",
        "        return NSphere(bound.empty_center, 0.0)\n",
        "    return NSphere(bound.centers[-1], bound.square_radii[-1])\n",
        " \n",
        "def _welzl(pts, pos, bdry):\n",
        "    support_count, nsphere = 0, makeNSphere(bdry)\n",
        "    if ismaxlength(bdry):\n",
        "        return nsphere, 0\n",
        "    for i in range(pos):\n",
        "        if not isinside(pts[i], nsphere):\n",
        "            isstable = push_if_stable(bdry, pts[i])\n",
        "            if isstable:\n",
        "                nsphere, s = _welzl(pts, i, bdry)\n",
        "                pop(bdry)\n",
        "                move_to_front(pts, i)\n",
        "                support_count = s + 1\n",
        "    return nsphere, support_count\n",
        " \n",
        "def find_max_excess(nsphere, pts, k1):\n",
        "    err_max, k_max = -np.Inf, k1 - 1\n",
        "    for (k, pt) in enumerate(pts[k_max:]):\n",
        "        err = sqdist(pt, nsphere.center) - nsphere.sqradius\n",
        "        if  err > err_max:\n",
        "            err_max, k_max = err, k + k1\n",
        "    return err_max, k_max - 1\n",
        " \n",
        "def welzl(points, maxiterations=2000):\n",
        "    pts, eps = np.array(points, copy=True), np.finfo(float).eps\n",
        "    bdry, t = GaertnerBoundary(pts), 1\n",
        "    nsphere, s = _welzl(pts, t, bdry)\n",
        "    for i in range(maxiterations):\n",
        "        e, k = find_max_excess(nsphere, pts, t + 1)\n",
        "        if e <= eps:\n",
        "            break\n",
        "        pt = pts[k]\n",
        "        push_if_stable(bdry, pt)\n",
        "        nsphere_new, s_new = _welzl(pts, s, bdry)\n",
        "        pop(bdry)\n",
        "        move_to_front(pts, k)\n",
        "        nsphere = nsphere_new\n",
        "        t, s = s + 1, s_new + 1\n",
        "    return nsphere"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuSs-sO9h_P3"
      },
      "source": [
        "RESULT_DIR = '/content/drive/MyDrive/Colab/SummaryCSV/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WoxoIYfWRc2"
      },
      "source": [
        "CSV_DIR = '/content/drive/MyDrive/Colab/RefinedCSV/'\n",
        "# 20211012 to 20211023\n",
        "TARGET_DATE = '20211012'\n",
        "\n",
        "TARGET_CSV = pd.read_csv(os.path.join(CSV_DIR, TARGET_DATE + '_PhoneGPS-AlphaPose-Device-Output.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrJbTg3QXFmi"
      },
      "source": [
        "TARGET_CSV = TARGET_CSV[(TARGET_CSV['lat'] != 0) & \n",
        "           (TARGET_CSV['lon'] != 0) &\n",
        "           (TARGET_CSV['lat'] == TARGET_CSV['lat']) &\n",
        "           (TARGET_CSV['lon'] == TARGET_CSV['lon'])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkSlAU5RezLA"
      },
      "source": [
        "segments = list(TARGET_CSV.groupby('segment_name'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY5IT7KCe-Jq"
      },
      "source": [
        "segments_dict = {}\n",
        "\n",
        "for segment in segments:\n",
        "  if not segment[0] in segments_dict:\n",
        "    segments_dict.update({segment[0] : None})\n",
        "  segments_dict[segment[0]] = list(segment[1].groupby('minutes'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-pbEmOHV7B9"
      },
      "source": [
        "df_return = pd.DataFrame()\n",
        "\n",
        "for key in segments_dict.keys():\n",
        "  for _, curr_min in segments_dict[key]:\n",
        "    points = pd.concat([curr_min['lat'], curr_min['lon']], axis=1)\n",
        "    nsphere = welzl(points.values)\n",
        "\n",
        "    start_row = curr_min.iloc[0]\n",
        "    end_row = curr_min.iloc[-1]\n",
        "\n",
        "    segment_name = start_row['segment_name']\n",
        "    minute = start_row['minutes']\n",
        "    second_data_count = len(curr_min)\n",
        "\n",
        "    #start_ad = start_row['ad_id']\n",
        "    #start_ad_count = (curr_min['ad_id'] == start_row['ad_id']).sum()\n",
        "    #end_ad = end_row['ad_id']\n",
        "    #end_ad_count = (curr_min['ad_id'] == end_row['ad_id']).sum()\n",
        "\n",
        "    ad_id_list = curr_min['ad_id'].unique()\n",
        "    ad_id_count = []\n",
        "\n",
        "    for ad in ad_id_list:\n",
        "      ad_id_count.append((curr_min['ad_id'] == ad).sum())\n",
        "\n",
        "    start_timestamp = start_row['timestamp']\n",
        "    end_timestamp = end_row['timestamp']\n",
        "\n",
        "    start_hour = start_row['time_hour']\n",
        "    start_minute = start_row['time_minute']\n",
        "    end_hour = end_row['time_hour']\n",
        "    end_minute = end_row['time_minute']\n",
        "\n",
        "    geo_points_center_lat = nsphere.center[0]\n",
        "    geo_points_center_lon = nsphere.center[1]\n",
        "\n",
        "    geo_points = list(zip(curr_min['lat'], curr_min['lon'], curr_min['alt'], curr_min['speed']))\n",
        "    #dong_based_geo = curr_min['dong'].values\n",
        "\n",
        "    illuminance = curr_min['illuminance'].mean()\n",
        "\n",
        "    head_count = curr_min['head_count'].apply(lambda x: round(x) if x == x else x).iloc[0]\n",
        "\n",
        "    T_valid_count = curr_min['T_valid_count'].iloc[0]\n",
        "    T_front_count = curr_min['T_front_count'].iloc[0]\n",
        "    T_valid_second = curr_min['T_valid_second'].apply(lambda x: round(x, 2) if x == x else x).iloc[0]\n",
        "    T_front_second = curr_min['T_front_second'].apply(lambda x: round(x, 2) if x == x else x).iloc[0]\n",
        "  \n",
        "    T_attention1_count = curr_min['T_attention1_count'].iloc[0]\n",
        "    T_attention2_count = curr_min['T_attention2_count'].iloc[0]\n",
        "    T_attention1_second = curr_min['T_attention1_second'].apply(lambda x: round(x, 2) if x == x else x).iloc[0]\n",
        "    T_attention2_second = curr_min['T_attention2_second'].apply(lambda x: round(x, 2) if x == x else x).iloc[0]\n",
        "    video_file = start_row['video_file']\n",
        "    \n",
        "\n",
        "    new_minute_summary_row = [segment_name, minute, second_data_count, ad_id_list, ad_id_count, start_timestamp, end_timestamp, start_hour, start_minute, end_hour, end_minute,\n",
        "                              geo_points_center_lat, geo_points_center_lon, geo_points, illuminance, head_count, T_valid_count, T_front_count,\n",
        "                              T_valid_second, T_front_second, T_attention1_count, T_attention2_count, T_attention1_second, T_attention2_second, video_file]\n",
        "    \n",
        "    df_minute = pd.Series(new_minute_summary_row, index=['segment_name', 'minute', 'second_data_count', 'ad_id_list', 'ad_id_count', 'start_timestamp', 'end_timestamp', 'start_hour', 'start_minute',\n",
        "                                  'end_hour', 'end_minute', 'geo_points_center_lat', 'geo_points_center_lon', 'geo_points',\n",
        "                                  'illuminance', 'head_count', 'T_valid_count', 'T_front_count' ,'T_valid_second', 'T_front_second', 'T_attention1_count', 'T_attention2_count',\n",
        "                                  'T_attention1_second', 'T_attention2_second', 'video_file']).to_frame(0).T\n",
        "\n",
        "    '''\n",
        "    new_minute_summary_row = [segment_name, minute, second_data_count, ad_id_list, ad_id_count, start_timestamp, end_timestamp, start_hour, start_minute, end_hour, end_minute,\n",
        "                              geo_points_center_lat, geo_points_center_lon, geo_points, dong_based_geo, illuminance, head_count,\n",
        "                              T_valid_second, T_front_second, T_attention1_count, T_attention2_count, T_attention1_second, T_attention2_second, video_file]\n",
        "    \n",
        "    df_minute = pd.Series(new_minute_summary_row, index=['segment_name', 'minute', 'second_data_count', 'ad_id_list', 'ad_id_count', 'start_timestamp', 'end_timestamp', 'start_hour', 'start_minute',\n",
        "                                  'end_hour', 'end_minute', 'geo_points_center_lat', 'geo_points_center_lon', 'geo_points',\n",
        "                                  'dong_based_geo', 'illuminance', 'head_count', 'T_valid_second', 'T_front_second', 'T_attention1_count', 'T_attention2_count',\n",
        "                                  'T_attention1_second', 'T_attention2_second', 'video_file']).to_frame(0).T\n",
        "    '''\n",
        "\n",
        "    df_return = pd.concat([df_return, df_minute], axis=0, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muc2kd-L8d3D"
      },
      "source": [
        "# #@title AB Test\n",
        "# df_return = pd.DataFrame()\n",
        "\n",
        "# for key in segments_dict.keys():\n",
        "#   for _, curr_min in segments_dict[key]:\n",
        "#     points = pd.concat([curr_min['lat'], curr_min['lon']], axis=1)\n",
        "#     nsphere = welzl(points.values)\n",
        "\n",
        "#     start_row = curr_min.iloc[0]\n",
        "#     end_row = curr_min.iloc[-1]\n",
        "\n",
        "#     segment_name = start_row['segment_name']\n",
        "#     minute = start_row['minutes']\n",
        "#     second_data_count = len(curr_min)\n",
        "\n",
        "#     start_ad = start_row['ad_id']\n",
        "#     start_ad_count = (curr_min['ad_id'] == start_row['ad_id']).sum()\n",
        "#     end_ad = end_row['ad_id']\n",
        "#     end_ad_count = (curr_min['ad_id'] == end_row['ad_id']).sum()\n",
        "\n",
        "#     start_timestamp = start_row['timestamp']\n",
        "#     end_timestamp = end_row['timestamp']\n",
        "\n",
        "#     start_hour = start_row['time_hour']\n",
        "#     start_minute = start_row['time_minute']\n",
        "#     end_hour = end_row['time_hour']\n",
        "#     end_minute = end_row['time_minute']\n",
        "\n",
        "#     geo_points_center_lat = nsphere.center[0]\n",
        "#     geo_points_center_lon = nsphere.center[1]\n",
        "\n",
        "#     geo_points = list(zip(curr_min['lat'], curr_min['lon'], curr_min['alt'], curr_min['speed']))\n",
        "#     dong_based_geo = curr_min['dong'].values\n",
        "\n",
        "#     illuminance = curr_min['illuminance'].mean()\n",
        "\n",
        "#     head_count = curr_min['head_count'].apply(lambda x: round(x) if x == x else x).iloc[0]\n",
        "#     T_valid_second = curr_min['T_valid_second'].apply(lambda x: round(x, 2) if x == x else x).iloc[0]\n",
        "#     T_front_second = curr_min['T_front_second'].apply(lambda x: round(x, 2) if x == x else x).iloc[0]\n",
        "#     T_attention1_count = curr_min['T_attention1_count'].iloc[0]\n",
        "#     T_attention2_count = curr_min['T_attention2_count'].iloc[0]\n",
        "#     T_attention1_second = curr_min['T_attention1_second'].apply(lambda x: round(x, 2) if x == x else x).iloc[0]\n",
        "#     T_attention2_second = curr_min['T_attention2_second'].apply(lambda x: round(x, 2) if x == x else x).iloc[0]\n",
        "#     video_file = start_row['video_file']\n",
        "    \n",
        "\n",
        "#     new_minute_summary_row = [segment_name, minute, second_data_count, start_ad, end_ad, start_ad_count, end_ad_count, start_timestamp, end_timestamp, start_hour, start_minute, end_hour, end_minute,\n",
        "#                               geo_points_center_lat, geo_points_center_lon, geo_points, dong_based_geo, illuminance, head_count,\n",
        "#                               T_valid_second, T_front_second, T_attention1_count, T_attention2_count, T_attention1_second, T_attention2_second, video_file]\n",
        "    \n",
        "#     df_minute = pd.Series(new_minute_summary_row, index=['segment_name', 'minute', 'second_data_count', 'start_ad', 'end_ad', 'start_ad_count', 'end_ad_count', 'start_timestamp', 'end_timestamp', 'start_hour', 'start_minute',\n",
        "#                                   'end_hour', 'end_minute', 'geo_points_center_lat', 'geo_points_center_lon', 'geo_points',\n",
        "#                                   'dong_based_geo', 'illuminance', 'head_count', 'T_valid_second', 'T_front_second', 'T_attention1_count', 'T_attention2_count',\n",
        "#                                   'T_attention1_second', 'T_attention2_second', 'video_file']).to_frame(0).T\n",
        "\n",
        "\n",
        "#     df_return = pd.concat([df_return, df_minute], axis=0, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxIT2l3uSPDh"
      },
      "source": [
        "# df_return[df_return['start_ad'] != df_return['end_ad']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCrF3u9xh7Z2"
      },
      "source": [
        "df_return.to_csv(os.path.join(RESULT_DIR, TARGET_DATE + '-SummaryCSV.csv'), index=False, encoding=\"utf-8-sig\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLAkzj6P8H25"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG64JzJrQ5l7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6yowKU2gaoF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}